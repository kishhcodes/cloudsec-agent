#!/usr/bin/env python3
"""
Comprehensive End-to-End Test Suite for Cloud Security Agent

Tests all major features including:
- Export functionality (JSON, CSV, HTML)
- Remediation playbooks
- CLI command integration
- Agent functionality
- Email service
- Playbook execution
"""

import os
import sys
import json
import time
from pathlib import Path
from datetime import datetime

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.syntax import Syntax
from rich import box
from rich.progress import Progress, SpinnerColumn, TextColumn

# Import modules
from src.audit.exporters import JSONExporter, CSVExporter, HTMLExporter, EmailService
from src.remediation import PlaybookExecutor, PlaybookLibrary, RemediationPlaybook, PlaybookStatus

console = Console()

# Test data
SAMPLE_REPORT = {
    "id": "test-audit-001",
    "timestamp": datetime.now().isoformat(),
    "account": "123456789012",
    "region": "us-east-1",
    "findings": [
        {
            "id": "FIND-001",
            "severity": "CRITICAL",
            "category": "Storage",
            "title": "Public S3 Bucket Detected",
            "resource": "my-public-bucket",
            "description": "S3 bucket is publicly accessible",
            "remediation": "Restrict bucket policy",
            "compliance": ["CIS AWS", "HIPAA"]
        },
        {
            "id": "FIND-002",
            "severity": "HIGH",
            "category": "Compute",
            "title": "Unencrypted EBS Volume",
            "resource": "vol-12345abc",
            "description": "EBS volume does not have encryption enabled",
            "remediation": "Enable EBS encryption",
            "compliance": ["PCI-DSS", "SOC2"]
        },
        {
            "id": "FIND-003",
            "severity": "HIGH",
            "category": "Security",
            "title": "Open Security Group Rule",
            "resource": "sg-98765def",
            "description": "Security group allows 0.0.0.0/0 on port 22",
            "remediation": "Restrict to specific IPs",
            "compliance": ["CIS AWS"]
        },
        {
            "id": "FIND-004",
            "severity": "MEDIUM",
            "category": "IAM",
            "title": "Root Account Access Key",
            "resource": "root-user",
            "description": "Root account has active access keys",
            "remediation": "Rotate or delete root access keys",
            "compliance": ["CIS AWS", "HIPAA"]
        }
    ],
    "statistics": {
        "total_findings": 4,
        "critical": 1,
        "high": 2,
        "medium": 1,
        "low": 0,
        "resources_scanned": 143,
        "compliance_score": 65
    }
}


def test_json_export():
    """Test JSON export functionality."""
    console.print("\n[bold cyan]TEST 1: JSON Export[/bold cyan]")
    
    try:
        exporter = JSONExporter()
        output_file = "reports/test_export.json"
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("Exporting to JSON...", total=None)
            result = exporter.export_report(SAMPLE_REPORT, output_file)
            progress.stop_task(task)
        
        # Verify file exists
        if os.path.exists(output_file):
            file_size = os.path.getsize(output_file)
            with open(output_file) as f:
                data = json.load(f)
            
            console.print(f"‚úÖ JSON export successful")
            console.print(f"   ‚Ä¢ File: {output_file}")
            console.print(f"   ‚Ä¢ Size: {file_size} bytes")
            console.print(f"   ‚Ä¢ Findings: {len(data.get('findings', []))}")
            return True
        else:
            console.print(f"‚ùå File not created: {output_file}")
            return False
            
    except Exception as e:
        console.print(f"‚ùå Error: {str(e)}")
        return False


def test_csv_export():
    """Test CSV export functionality."""
    console.print("\n[bold cyan]TEST 2: CSV Export[/bold cyan]")
    
    try:
        exporter = CSVExporter()
        
        # Test findings export
        output_file = "reports/test_findings.csv"
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("Exporting findings to CSV...", total=None)
            exporter.export_findings_to_csv(SAMPLE_REPORT["findings"], output_file)
            progress.stop_task(task)
        
        if os.path.exists(output_file):
            file_size = os.path.getsize(output_file)
            with open(output_file) as f:
                lines = f.readlines()
            
            console.print(f"‚úÖ Findings CSV export successful")
            console.print(f"   ‚Ä¢ File: {output_file}")
            console.print(f"   ‚Ä¢ Size: {file_size} bytes")
            console.print(f"   ‚Ä¢ Rows: {len(lines)}")
            
            # Test tracker export
            tracker_file = "reports/test_tracker.csv"
            exporter.export_remediation_tracker_to_csv(SAMPLE_REPORT["findings"], tracker_file)
            
            if os.path.exists(tracker_file):
                console.print(f"‚úÖ Tracker CSV export successful")
                console.print(f"   ‚Ä¢ File: {tracker_file}")
            
            return True
        else:
            console.print(f"‚ùå File not created: {output_file}")
            return False
            
    except Exception as e:
        console.print(f"‚ùå Error: {str(e)}")
        return False


def test_html_export():
    """Test HTML export functionality."""
    console.print("\n[bold cyan]TEST 3: HTML Export[/bold cyan]")
    
    try:
        exporter = HTMLExporter()
        output_file = "reports/test_report.html"
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("Exporting to HTML...", total=None)
            exporter.export_email_template(SAMPLE_REPORT, output_file)
            progress.stop_task(task)
        
        if os.path.exists(output_file):
            file_size = os.path.getsize(output_file)
            with open(output_file) as f:
                content = f.read()
            
            console.print(f"‚úÖ HTML export successful")
            console.print(f"   ‚Ä¢ File: {output_file}")
            console.print(f"   ‚Ä¢ Size: {file_size} bytes")
            console.print(f"   ‚Ä¢ Contains findings: {'Finding' in content}")
            return True
        else:
            console.print(f"‚ùå File not created: {output_file}")
            return False
            
    except Exception as e:
        console.print(f"‚ùå Error: {str(e)}")
        return False


def test_playbook_library():
    """Test playbook library functionality."""
    console.print("\n[bold cyan]TEST 4: Playbook Library[/bold cyan]")
    
    try:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("Loading playbooks...", total=None)
            playbooks = PlaybookLibrary.get_all_playbooks()
            progress.stop_task(task)
        
        console.print(f"‚úÖ Loaded {len(playbooks)} playbooks")
        
        # Display table
        table = Table(title="Available Playbooks", box=box.ROUNDED)
        table.add_column("Name", style="cyan")
        table.add_column("Category", style="magenta")
        table.add_column("Severity", style="yellow")
        
        severity_map = {
            "CRITICAL": "[bold red]CRITICAL[/bold red]",
            "HIGH": "[bold orange]HIGH[/bold orange]",
            "MEDIUM": "[bold yellow]MEDIUM[/bold yellow]",
            "LOW": "[bold green]LOW[/bold green]"
        }
        
        for name, pb in list(playbooks.items())[:5]:  # Show first 5
            severity = severity_map.get(pb.severity, pb.severity)
            table.add_row(pb.name, pb.category, severity)
        
        console.print(table)
        
        # Test filtering
        critical_playbooks = PlaybookLibrary.get_playbooks_by_severity("CRITICAL")
        console.print(f"‚úÖ Found {len(critical_playbooks)} CRITICAL playbooks")
        
        storage_playbooks = PlaybookLibrary.get_playbook_by_category("Storage")
        console.print(f"‚úÖ Found {len(storage_playbooks)} Storage playbooks")
        
        return True
        
    except Exception as e:
        console.print(f"‚ùå Error: {str(e)}")
        return False


def test_playbook_execution():
    """Test playbook execution with approval workflow."""
    console.print("\n[bold cyan]TEST 5: Playbook Execution[/bold cyan]")
    
    try:
        executor = PlaybookExecutor()
        playbooks = PlaybookLibrary.get_all_playbooks()
        playbook = playbooks["AWS-PUBLIC-S3"]
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("Executing playbook (dry-run)...", total=None)
            
            execution = executor.execute_playbook(
                playbook=playbook,
                finding_data={"id": "FIND-001", "resource": "test-bucket"},
                initiated_by="test-user",
                dry_run=True
            )
            progress.stop_task(task)
        
        console.print(f"‚úÖ Playbook executed successfully")
        console.print(f"   ‚Ä¢ Execution ID: {execution.execution_id}")
        console.print(f"   ‚Ä¢ Status: {execution.status.value}")
        console.print(f"   ‚Ä¢ Playbook: {execution.playbook_name}")
        console.print(f"   ‚Ä¢ Actions: {len(execution.actions)}")
        console.print(f"   ‚Ä¢ Dry-run: {execution.dry_run}")
        
        # Test approval workflow
        console.print(f"\n   Testing approval workflow...")
        if execution.approval_status == "AWAITING_APPROVAL":
            executor.approve_execution(execution.execution_id, "test-approver")
            console.print(f"   ‚úÖ Execution approved")
        else:
            console.print(f"   ‚ÑπÔ∏è  No approval needed for dry-run execution")
        
        # Get history
        history = executor.get_execution_history(limit=5)
        console.print(f"   ‚úÖ Retrieved {len(history)} executions from history")
        
        return True
        
    except Exception as e:
        console.print(f"‚ùå Error: {str(e)}")
        return False


def test_email_service():
    """Test email service configuration."""
    console.print("\n[bold cyan]TEST 6: Email Service[/bold cyan]")
    
    try:
        email_service = EmailService()
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("Testing email configuration...", total=None)
            config = email_service.test_connection()
            progress.stop_task(task)
        
        console.print(f"‚úÖ Email service instantiated")
        console.print(f"   ‚Ä¢ SMTP Server: {config.get('smtp_server', 'Not configured')}")
        console.print(f"   ‚Ä¢ Sender Email: {config.get('sender_email', 'Not configured')}")
        console.print(f"   ‚Ä¢ Status: {config.get('status', 'Not configured')}")
        
        if config.get('configured', False):
            console.print(f"   ‚úÖ Email service is fully configured")
        else:
            console.print(f"   ‚ö†Ô∏è  Email service requires configuration")
            console.print(f"      Set SMTP_SERVER, SENDER_EMAIL, SENDER_PASSWORD env vars")
        
        return True
        
    except Exception as e:
        console.print(f"‚ùå Error: {str(e)}")
        return False


def test_cloud_agents():
    """Test cloud agent integration."""
    console.print("\n[bold cyan]TEST 7: Cloud Agent Integration[/bold cyan]")
    
    try:
        # Test AWS Agent
        console.print("\n   Testing AWS Agent...")
        try:
            from src.agents.aws_security.agent import AWSSecurityAgent
            aws_agent = AWSSecurityAgent()
            console.print(f"   ‚úÖ AWS Agent imported and instantiated")
            
            # Test export method exists
            if hasattr(aws_agent, 'export_report'):
                console.print(f"      ‚úÖ export_report method available")
            if hasattr(aws_agent, 'remediate_finding'):
                console.print(f"      ‚úÖ remediate_finding method available")
        except Exception as e:
            console.print(f"   ‚ö†Ô∏è  AWS Agent: {str(e)}")
        
        # Test GCP Agent
        console.print("\n   Testing GCP Agent...")
        try:
            from src.agents.gcp_security.agent import GCPSecurityAgent
            # Don't instantiate as it requires real GCP credentials
            console.print(f"   ‚úÖ GCP Agent imported")
            
            if hasattr(GCPSecurityAgent, 'export_report'):
                console.print(f"      ‚úÖ export_report method available")
            if hasattr(GCPSecurityAgent, 'remediate_finding'):
                console.print(f"      ‚úÖ remediate_finding method available")
        except Exception as e:
            console.print(f"   ‚ö†Ô∏è  GCP Agent: {str(e)}")
        
        # Test Azure Agent
        console.print("\n   Testing Azure Agent...")
        try:
            from src.agents.azure_security.agent import AzureSecurityAgent
            # Don't instantiate as it requires real Azure credentials
            console.print(f"   ‚úÖ Azure Agent imported")
            
            if hasattr(AzureSecurityAgent, 'export_report'):
                console.print(f"      ‚úÖ export_report method available")
            if hasattr(AzureSecurityAgent, 'remediate_finding'):
                console.print(f"      ‚úÖ remediate_finding method available")
        except Exception as e:
            console.print(f"   ‚ö†Ô∏è  Azure Agent: {str(e)}")
        
        return True
        
    except Exception as e:
        console.print(f"‚ùå Error: {str(e)}")
        return False


def test_end_to_end_workflow():
    """Test complete end-to-end workflow."""
    console.print("\n[bold cyan]TEST 8: End-to-End Workflow[/bold cyan]")
    
    try:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            # Step 1: Export report
            task = progress.add_task("Step 1: Exporting report...", total=None)
            exporter = JSONExporter()
            exporter.export_report(SAMPLE_REPORT, "reports/e2e_workflow.json")
            progress.update(task, completed=True)
            time.sleep(0.5)
            
            # Step 2: Execute playbook
            task = progress.add_task("Step 2: Executing remediation...", total=None)
            executor = PlaybookExecutor()
            playbooks = PlaybookLibrary.get_all_playbooks()
            execution = executor.execute_playbook(
                playbook=playbooks["AWS-PUBLIC-S3"],
                finding_data={"id": "FIND-001", "resource": "test-bucket"},
                initiated_by="e2e-test",
                dry_run=True
            )
            progress.update(task, completed=True)
            time.sleep(0.5)
            
            # Step 3: Approve execution
            task = progress.add_task("Step 3: Approving execution...", total=None)
            executor.approve_execution(execution.execution_id, "e2e-approver")
            progress.update(task, completed=True)
            time.sleep(0.5)
            
            # Step 4: Generate summary
            task = progress.add_task("Step 4: Generating summary...", total=None)
            history = executor.get_execution_history(limit=1)
            progress.update(task, completed=True)
        
        console.print(f"‚úÖ E2E Workflow completed successfully")
        console.print(f"   ‚Ä¢ Report exported: reports/e2e_workflow.json")
        console.print(f"   ‚Ä¢ Playbook executed: {execution.playbook_name}")
        console.print(f"   ‚Ä¢ Execution approved: {execution.execution_id}")
        console.print(f"   ‚Ä¢ History retrieved: {len(history)} items")
        
        return True
        
    except Exception as e:
        console.print(f"‚ùå Error: {str(e)}")
        return False


def run_query_tests():
    """Run specific query tests."""
    console.print("\n[bold cyan]TEST 9: Query Validation Tests[/bold cyan]")
    
    results = []
    
    # Query 1: Find CRITICAL findings
    console.print("\n   Query 1: Find all CRITICAL severity findings")
    critical = [f for f in SAMPLE_REPORT["findings"] if f["severity"] == "CRITICAL"]
    console.print(f"   ‚úÖ Found {len(critical)} CRITICAL findings")
    for finding in critical:
        console.print(f"      ‚Ä¢ {finding['title']}")
    results.append(len(critical) > 0)
    
    # Query 2: Find findings by category
    console.print("\n   Query 2: Find findings by Storage category")
    storage = [f for f in SAMPLE_REPORT["findings"] if f["category"] == "Storage"]
    console.print(f"   ‚úÖ Found {len(storage)} Storage findings")
    for finding in storage:
        console.print(f"      ‚Ä¢ {finding['title']}")
    results.append(len(storage) > 0)
    
    # Query 3: Find findings by compliance
    console.print("\n   Query 3: Find findings related to CIS AWS")
    cis_findings = [f for f in SAMPLE_REPORT["findings"] if "CIS AWS" in f.get("compliance", [])]
    console.print(f"   ‚úÖ Found {len(cis_findings)} CIS AWS findings")
    for finding in cis_findings:
        console.print(f"      ‚Ä¢ {finding['title']}")
    results.append(len(cis_findings) > 0)
    
    # Query 4: Get remediation summary
    console.print("\n   Query 4: Get remediation requirements")
    console.print(f"   ‚úÖ Remediation required for {len(SAMPLE_REPORT['findings'])} findings:")
    for finding in SAMPLE_REPORT["findings"]:
        console.print(f"      ‚Ä¢ {finding['title']}: {finding['remediation']}")
    results.append(len(SAMPLE_REPORT["findings"]) > 0)
    
    # Query 5: Get compliance summary
    console.print("\n   Query 5: Get compliance status")
    all_compliance = set()
    for finding in SAMPLE_REPORT["findings"]:
        all_compliance.update(finding.get("compliance", []))
    console.print(f"   ‚úÖ Frameworks affected: {', '.join(sorted(all_compliance))}")
    results.append(len(all_compliance) > 0)
    
    return all(results)


def main():
    """Run all tests."""
    console.print(Panel.fit(
        "[bold cyan]Cloud Security Agent - Comprehensive Test Suite[/bold cyan]",
        border_style="cyan"
    ))
    
    # Create reports directory
    os.makedirs("reports", exist_ok=True)
    
    # Run all tests
    tests = [
        ("JSON Export", test_json_export),
        ("CSV Export", test_csv_export),
        ("HTML Export", test_html_export),
        ("Playbook Library", test_playbook_library),
        ("Playbook Execution", test_playbook_execution),
        ("Email Service", test_email_service),
        ("Cloud Agents", test_cloud_agents),
        ("E2E Workflow", test_end_to_end_workflow),
        ("Query Tests", run_query_tests),
    ]
    
    results = {}
    for test_name, test_func in tests:
        try:
            result = test_func()
            results[test_name] = result
        except Exception as e:
            console.print(f"\n‚ùå Test '{test_name}' failed: {str(e)}")
            results[test_name] = False
    
    # Summary
    console.print("\n" + "="*80)
    console.print("[bold cyan]TEST SUMMARY[/bold cyan]")
    console.print("="*80)
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    summary_table = Table(box=box.ROUNDED)
    summary_table.add_column("Test", style="cyan")
    summary_table.add_column("Result", style="green")
    
    for test_name, result in results.items():
        status = "‚úÖ PASSED" if result else "‚ùå FAILED"
        summary_table.add_row(test_name, status)
    
    console.print(summary_table)
    
    console.print(f"\n[bold cyan]Results: {passed}/{total} tests passed ({int(passed/total*100)}%)[/bold cyan]")
    
    if passed == total:
        console.print("\n[bold green]üéâ ALL TESTS PASSED! üéâ[/bold green]")
        console.print("\nThe Cloud Security Agent is fully functional and ready for deployment!")
        return 0
    else:
        console.print(f"\n[bold yellow]‚ö†Ô∏è  {total - passed} test(s) failed[/bold yellow]")
        return 1


if __name__ == "__main__":
    sys.exit(main())
